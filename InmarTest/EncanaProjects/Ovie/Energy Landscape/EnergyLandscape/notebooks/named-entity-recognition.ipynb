{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELM Proof of Concept #3 : Named Entity Recognition\n",
    "\n",
    "* October 30th, 2018\n",
    "* Ryan Kazmerik, Strategic EIM\n",
    "\n",
    "## Hypothesis\n",
    "Named entity recognition can be used to extract meaningful pieces of information (tags) from our articles, which can then be used to create relationships with other topics and/or articles.\n",
    "\n",
    "We will test this hypothesis using three popular NER implementations and our ~15,000 news articles from the News-API dataset.\n",
    "\n",
    "### Research\n",
    "**1. NLTK (Natural Language Toolkit)**\n",
    "* popular open source library\n",
    "* uses POS (part-of-speech) tagging to extract entities\n",
    "* very fast, but not as accurate as other implementations\n",
    "<br/>[Testing NER taggers for speed/accuracy](https://pythonprogramming.net/testing-stanford-ner-taggers-for-speed/?completed=/testing-stanford-ner-taggers-for-accuracy)<br/><br/>\n",
    "\n",
    "**2. Stanford NER**\n",
    "* developed by NLP lab at Stanford\n",
    "* uses CRF (conditional random fields) for extracting entities\n",
    "* most accurate, often seen as the gold-standard\n",
    "<br/>[NER for Unstructured Documents](https://medium.com/@dudsdu/named-entity-recognition-for-unstructured-documents-c325d47c7e3a)<br/><br/>\n",
    "\n",
    "**3. SpaCy**\n",
    "* supported open source by Explosion AI\n",
    "* uses CNN (conv neural network) for extracting entities\n",
    "* mixture of accuracy and speed & lots of entity types\n",
    "<br/>[SpaCy NER - Lingustic Features](https://spacy.io/usage/linguistic-features#section-named-entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "We will measure the speed and total number of extracted entities for all 3 implementations. Let's load in our ~15,000 articles from Elastic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. training articles: 14512\n",
      "\n",
      "Sample description: A private equity firm backed by some of the world’s largest utilities has raised $681 million to finance startups developing clean-energy technology.\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch()\n",
    "\n",
    "docs = es.search(\n",
    "    index='articles', \n",
    "    doc_type='article',\n",
    "    filter_path=['hits.hits'],\n",
    "    _source_include='description,title',\n",
    "    sort='_id',\n",
    "    size=20000\n",
    ")\n",
    "\n",
    "articles = []\n",
    "\n",
    "for i,d in enumerate(docs['hits']['hits']):\n",
    "    desc = (d[\"_source\"][\"description\"])\n",
    "    if(desc):\n",
    "        articles.append(desc)\n",
    "    i+=1;\n",
    "    \n",
    "print(\"No. training articles:\",len(articles))\n",
    "print()\n",
    "print(\"Sample description:\",articles[21])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK\n",
    "**Let's start with implementing the NLTK tagger**\n",
    "\n",
    "First we need to tokenize the text (split each sentence into words), and tag each word with it's part of speech (ex. gained = verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk import pos_tag\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "def process_text(article):\n",
    "    token_text = word_tokenize(article)\n",
    "    return token_text\n",
    "\n",
    "# NLTK tagger   \n",
    "def nltk_tagger(token_text):\n",
    "    tagged_words = nltk.pos_tag(token_text)\n",
    "    ne_tagged = nltk.ne_chunk(tagged_words)\n",
    "    return(ne_tagged)\n",
    "\n",
    "# Stanford NER tagger    \n",
    "def stanford_tagger(token_text):\n",
    "    st = StanfordNERTagger('../classes/english.all.3class.distsim.crf.ser.gz',\n",
    "                            '../classes/stanford-ner.jar',\n",
    "                            encoding='utf-8')   \n",
    "    ne_tagged = st.tag(token_text)\n",
    "    return(ne_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All NER taggers include 3 types of tags: PERSON, LOCATION and ORGANIZATION.**\n",
    "\n",
    "Let's run the NER tagger for NLTK, Stanford and SpaCy and see an example result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK results: (S\n",
      "  In/IN\n",
      "  (GPE Oregon/NNP)\n",
      "  ,/,\n",
      "  (GPE Illinois/NNP)\n",
      "  ,/,\n",
      "  an/DT\n",
      "  old/JJ\n",
      "  farmhouse/NN\n",
      "  just/RB\n",
      "  outside/IN\n",
      "  of/IN\n",
      "  town/NN\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  hotbed/NN\n",
      "  of/IN\n",
      "  alternative/JJ\n",
      "  energy/NN\n",
      "  ./.\n",
      "  It/PRP\n",
      "  's/VBZ\n",
      "  primarily/RB\n",
      "  heated/VBN\n",
      "  by/IN\n",
      "  wood/NN\n",
      "  and/CC\n",
      "  they/PRP\n",
      "  have/VBP\n",
      "  a/DT\n",
      "  wind/NN\n",
      "  generator/NN\n",
      "  ,/,\n",
      "  although/IN\n",
      "  it/PRP\n",
      "  's/VBZ\n",
      "  mainly/RB\n",
      "  used/VBN\n",
      "  for/IN\n",
      "  educational/JJ\n",
      "  purposes/NNS\n",
      "  ./.)\n",
      "\n",
      "Stanford results: [('In', 'O'), ('Oregon', 'LOCATION'), (',', 'O'), ('Illinois', 'LOCATION'), (',', 'O'), ('an', 'O'), ('old', 'O'), ('farmhouse', 'O'), ('just', 'O'), ('outside', 'O'), ('of', 'O'), ('town', 'O'), ('is', 'O'), ('a', 'O'), ('hotbed', 'O'), ('of', 'O'), ('alternative', 'O'), ('energy', 'O'), ('.', 'O'), ('It', 'O'), (\"'s\", 'O'), ('primarily', 'O'), ('heated', 'O'), ('by', 'O'), ('wood', 'O'), ('and', 'O'), ('they', 'O'), ('have', 'O'), ('a', 'O'), ('wind', 'O'), ('generator', 'O'), (',', 'O'), ('although', 'O'), ('it', 'O'), (\"'s\", 'O'), ('mainly', 'O'), ('used', 'O'), ('for', 'O'), ('educational', 'O'), ('purposes', 'O'), ('.', 'O')]\n",
      "\n",
      "SpaCy results: In Oregon, Illinois, an old farmhouse just outside of town is a hotbed of alternative energy. It's primarily heated by wood and they have a wind generator, although it's mainly used for educational purposes.\n",
      "[('Oregon', 'GPE'), ('Illinois', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "NLTK = nltk_tagger(process_text(articles[22]))\n",
    "STAN = stanford_tagger(process_text(articles[22]))\n",
    "SPACY = nlp(articles[22])\n",
    "\n",
    "print(\"NLTK results:\",NLTK)\n",
    "print()\n",
    "print(\"Stanford results:\",STAN)\n",
    "print()\n",
    "print(\"SpaCy results:\",SPACY)\n",
    "print([(X.text, X.label_) for X in SPACY.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All 3 taggers correctly identified the same 2 entities (Oregon and Illinois) with the LOCATION tag.**\n",
    "\n",
    "Now, let's run all 3 taggers on 5, 10, 50, 100, 500, 1000, 5000 and 10000 articles and compare the number of total entities extracted and performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing.....\n",
      "Number of articles: 5\n",
      "NLTK found entities: 6 in: 0.06 seconds\n",
      "STAN found entities: 10 in: 9.19 seconds\n",
      "SpaCy found entities: 2 in: 0.08 seconds\n",
      "\n",
      "Number of articles: 10\n",
      "NLTK found entities: 19 in: 0.14 seconds\n",
      "STAN found entities: 30 in: 18.27 seconds\n",
      "SpaCy found entities: 6 in: 0.16 seconds\n",
      "\n",
      "Number of articles: 50\n",
      "NLTK found entities: 101 in: 0.56 seconds\n",
      "STAN found entities: 157 in: 91.92 seconds\n",
      "SpaCy found entities: 85 in: 0.78 seconds\n",
      "\n",
      "Number of articles: 100\n",
      "NLTK found entities: 274 in: 1.11 seconds\n",
      "STAN found entities: 463 in: 190.84 seconds\n",
      "SpaCy found entities: 279 in: 1.67 seconds\n",
      "\n",
      "Number of articles: 500\n",
      "NLTK found entities: 1183 in: 4.75 seconds\n",
      "STAN found entities: 1908 in: 973.96 seconds\n",
      "SpaCy found entities: 1360 in: 7.82 seconds\n",
      "\n",
      "Number of articles: 1000\n",
      "NLTK found entities: 2749 in: 8.05 seconds\n",
      "STAN found entities: 4142 in: 1909.95 seconds\n",
      "SpaCy found entities: 3137 in: 14.63 seconds\n",
      "\n",
      "Number of articles: 5000\n",
      "NLTK found entities: 13690 in: 41.57 seconds\n",
      "STAN found entities: 14381 in: 9599.02 seconds\n",
      "SpaCy found entities: 14870 in: 74.55 seconds\n",
      "\n",
      "Number of articles: 10000\n",
      "NLTK found entities: 31727 in: 78.27 seconds\n",
      "STAN found entities: 33480 in: 19149.99 seconds\n",
      "SpaCy found entities: 34374 in: 146.95 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NLTK_results = []\n",
    "STAN_results = []\n",
    "SPACY_results = []\n",
    "\n",
    "print(\"Processing.....\")\n",
    "\n",
    "n_articles = [5, 10, 50, 100, 500, 1000, 5000, 10000]\n",
    "\n",
    "results = []\n",
    "for n in n_articles:\n",
    "\n",
    "    t0 = time()\n",
    "    for i,a in enumerate(articles[:n]):\n",
    "        NLTK_results.append(nltk_tagger(process_text(a)))\n",
    "    NLTK_time = time()-t0\n",
    "\n",
    "    t0 = time()\n",
    "    for i,a in enumerate(articles[:n]):\n",
    "        STAN_results.append(stanford_tagger(process_text(a)))\n",
    "    STAN_time = time()-t0\n",
    "\n",
    "    t0 = time()\n",
    "    for i,a in enumerate(articles[:n]):\n",
    "        for X in nlp(a).ents:\n",
    "            SPACY_results.append([(X.text, X.label_)])\n",
    "    SPACY_time = time()-t0\n",
    "\n",
    "    NLTK_ents = []\n",
    "    for tagged in (NLTK_results):\n",
    "        for tag in tagged:\n",
    "            if(len(tag)==1):\n",
    "                NLTK_ents.append(tag)\n",
    "\n",
    "    STAN_ents = []\n",
    "    for tagged in (STAN_results):\n",
    "        for tag in tagged:\n",
    "            if(tag[1]==\"GPE\" or tag[1]==\"PERSON\" or tag[1]==\"ORGANIZATION\"):\n",
    "                STAN_ents.append(tag)\n",
    "    \n",
    "    SPACY_ents = []\n",
    "    for tagged in (SPACY_results):\n",
    "        e = tagged[0][1]\n",
    "        if(e==\"GPE\" or e==\"ORG\" or e==\"PERSON\"):\n",
    "            SPACY_ents.append(tagged)\n",
    "            \n",
    "    results.append([[len(NLTK_ents), len(STAN_ents), len(SPACY_ents)],[NLTK_time, STAN_time, SPACY_time]])\n",
    "    \n",
    "    print(\"Number of articles:\", n)\n",
    "    print(\"NLTK found entities:\", len(NLTK_ents), \"in:\", round(NLTK_time,2), 'seconds')\n",
    "    print(\"STAN found entities:\", len(STAN_ents), \"in:\", round(STAN_time,2), 'seconds')\n",
    "    print(\"SpaCy found entities:\", len(SPACY_ents), \"in:\", round(SPACY_time,2), 'seconds')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "**Extracting the entities took a lot longer using the Stanford NER tagger, this could be a significant factor in how we are able to implement NER within our NLP pipeline.**\n",
    "\n",
    "Let's have a look at how this performance scales as we process more articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~rkazmerik/368.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "nltk_x, nltk_y, stan_x, stan_y, spac_x, spac_y = [],[],[],[],[],[]\n",
    "\n",
    "for r in results:\n",
    "    nltk_x.append(r[0][0])\n",
    "    nltk_y.append(r[1][0])\n",
    "    stan_x.append(r[0][1])\n",
    "    stan_y.append(r[1][1])\n",
    "    spac_x.append(r[0][2])\n",
    "    spac_y.append(r[1][2])\n",
    "    \n",
    "trace1 = go.Scatter(name='NLTK', x=nltk_x, y=nltk_y)\n",
    "trace2 = go.Scatter(name='Stanford', x=stan_x, y=stan_y)\n",
    "trace3 = go.Scatter(name='SpaCy', x=spac_x, y=spac_y)\n",
    "\n",
    "data = [trace1, trace2, trace3]\n",
    "\n",
    "layout = go.Layout(title = 'No. Entities vs. Time',\n",
    "    yaxis = dict(title='Time in seconds'),\n",
    "    xaxis = dict(title='No. Entities'),\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Stanford NER tagger takes *significantly* longer as more documents are analyzed, reaching 18992.25 seconds for 10,000 articles which is almost 5 1/2 hours.\n",
    "* The NLTK tagger had the best performance, aprx 57% better than SpaCy.\n",
    "* SpaCy retrieved the most entities, aprx 8.5% more than NLTK.\n",
    "<br/><br/>\n",
    "\n",
    "**Because of the dramatic performance cost of the Stanford tagger, we will only consider NLTK and SpaCy.**\n",
    "\n",
    "Let's have a closer look at the quality of the entities for each method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample article: Yves Rannou, formerly president and chief executive officer of hydro for GE Renewable Energy, has taken a position as CEO of Senvion S.A., a manufacturer of wind turbines.\n",
      "\n",
      "NLTK results:\n",
      "(PERSON Rannou/NNP)\n",
      "(ORGANIZATION CEO/NNP)\n",
      "(ORGANIZATION Senvion/NNP)\n",
      "\n",
      "SpaCy results:\n",
      "('PERSON', 'Yves Rannou')\n",
      "('ORG', 'GE Renewable Energy')\n",
      "('ORG', 'Senvion S.A.')\n"
     ]
    }
   ],
   "source": [
    "k = 60\n",
    "\n",
    "NLTK = nltk_tagger(process_text(articles[k]))\n",
    "SPACY = nlp(articles[k])\n",
    "\n",
    "print(\"Sample article:\", articles[k], end=\"\\n\\n\")\n",
    "print(\"NLTK results:\")\n",
    "for tag in NLTK:\n",
    "    if(len(tag)==1):\n",
    "        print(tag)\n",
    "print()\n",
    "\n",
    "print(\"SpaCy results:\")\n",
    "for X in SPACY.ents:\n",
    "    if(X.label_==\"GPE\" or X.label_==\"ORG\" or X.label_==\"PERSON\"):\n",
    "        print((X.label_, X.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The quality of the SpaCy entities seems better than NLTK on this example becase:**\n",
    "* NLTK only identifies the last name of Yves Rannou, where as SpaCy identifies the whole name.\n",
    "* NLTK thinks 'CEO' is an organization.\n",
    "* NLTK only identifies the first part of the company Sevion S.A., where as SpaCy identifies the whole company name.\n",
    "* SpaCy identifies GE Renewable Energy as a company, where as NLTK does not.\n",
    "\n",
    "In addition, SpaCy can also identify 18 entity types, only 3 of which are available in NLTK. These entity types include:\n",
    "1. PERSON - People, including fictional.\n",
    "2. NORP - Nationalities or religious or political groups.\n",
    "3. FAC - Buildings, airports, highways, bridges, etc.\n",
    "4. ORG - Companies, agencies, institutions, etc.\n",
    "5. GPE - Countries, cities, states.\n",
    "6. LOC - Non-GPE locations, mountain ranges, bodies of water.\n",
    "7. PRODUCT - Objects, vehicles, foods, etc. (Not services.)\n",
    "8. EVENT - Named hurricanes, battles, wars, sports events, etc.\n",
    "9. WORK_OF_ART - Titles of books, songs, etc.\n",
    "10. LAW - Named documents made into laws.\n",
    "11. LANGUAGE - Any named language.\n",
    "12. DATE - Absolute or relative dates or periods.\n",
    "13. TIME - Times smaller than a day.\n",
    "14. PERCENT - Percentage, including \"%\".\n",
    "15. MONEY - Monetary values, including unit.\n",
    "16. QUANTITY - Measurements, as of weight or distance.\n",
    "17. ORDINAL - \"first\", \"second\", etc.\n",
    "18. CARDINAL - Numerals that do not fall under another type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To get a better sense of the SpaCy entities we can use the built in DisplaCy visualizer on a few sample articles:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    CenterPoint Energy Inc.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " wants to introduce a pilot program in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Minnesota\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " offering customers access to a renewable form of natural gas recovered from dairy farms and landfills.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">The report by recently rebranded \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Wind-Solar Alliance\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " points out that \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    more than 100\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    U.S.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " corporate buyers —members of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the Renewable Energy Buyers Alliance —\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " have set a goal of purchasing \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    60\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    GW\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " of new \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    U.S.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " renewable energy capacity by \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    2025\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". So far, since \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    2013\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", …</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Statkraft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " has announced it is planning \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    annual\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " investments of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    about NOK10 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    US$1.2 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ") in renewable energy from \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    2019\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " to \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    2025\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", including “large upgrades of \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Nordic\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " hydropower.”</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "displacy.render(nlp(articles[30]), jupyter=True, style='ent')\n",
    "print()\n",
    "print()\n",
    "displacy.render(nlp(articles[38]), jupyter=True, style='ent')\n",
    "print()\n",
    "print()\n",
    "displacy.render(nlp(articles[40]), jupyter=True, style='ent')\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "* The SpaCy NER tagger looks like the best mix of extracting quality entities and performance compared to NLTK and the Stanford NER.\n",
    "<br/><br/>\n",
    "\n",
    "* Entities could provide valuable relationships for building a classifier, but may need to be combined with other metadata (sentiment or topics) in order to be valuable.\n",
    "<br/><br/>\n",
    "\n",
    "* Incorprating the SpaCy NER tagger as part of our NLP pipeline would be efficient enough to process thousands if not millions of articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Improvements\n",
    "1. Could train new entity types for product (oil, gas, cbm, etc.) to help correlate with mentions of price increase / decrease.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
