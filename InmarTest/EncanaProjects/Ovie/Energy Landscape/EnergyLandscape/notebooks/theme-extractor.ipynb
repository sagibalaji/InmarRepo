{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"At the start of 2019, free cash flow, our inventory and lease operating expense on a unit basis was initially forecasted to be flat year-over-year. However, we now expect\n",
    "full year 2019 LOE to be 4% lower than 2018.\n",
    "At the midpoint of our 2019 DD&A guidance range of $12.65, we were on track to deliver the lowest rate since EOG's transition from a\n",
    "natural gas company to oil. Our permanent switch to premium drilling continues to transform the company, driving down finding and\n",
    "development costs, reducing D&A and enabling EOG to deliver double-digit returns throughout commodity price cycles.\n",
    "Also of note during the third quarter, we entered into long-term gas supply arrangements with Cheniere Energy. Consistent with our\n",
    "strategy of having flexibility and diversity in marketing our products, these arrangements provide additional markets for offtake and\n",
    "pricing diversity for up to 440 million BTU per day starting in 2020, with the ultimate goal of maximizing the realized price for our\n",
    "growing production of low-cost natural gas.\n",
    "Now I would like to provide some color on the Bakken and other Rockies plays. In the Bakken this quarter, we completed 15 wells with an\n",
    "average IP-30 of 2,150 barrels of oil per day, 300 barrels of NGLs and 2 million cubic feet a day of natural gas. Our strong well results\n",
    "reflect the impact of EOG precision targeting and our new completion techniques. The highlight for the quarter was the Clarks Creek 18\n",
    "well that was completed in the Three Forks with an IP-30 of 3,800 barrels of oil per day. This well is our best well to date in the Bakken,\n",
    "which along with strong performance from other wells completed this quarter, are a testament to the continued improvements we see\n",
    "across our entire inventory.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noun phrases using Textacy\n",
    "\n",
    "### Potential issues:\n",
    "* Some 1-word ngrams aren't that useful (Fixed by filtering for NOUN only)\n",
    "* But others like 'inventory' will be lost if limited to bi/tri-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free cash flow\n",
      "operating expense\n",
      "unit basis\n",
      "lowest rate\n",
      "premium drilling\n",
      "development costs\n",
      "commodity price cycles\n",
      "additional markets\n",
      "pricing diversity\n",
      "ultimate goal\n",
      "realized price\n",
      "natural gas\n",
      "strong performance\n",
      "continued improvements\n",
      "Total themes: 14\n"
     ]
    }
   ],
   "source": [
    "#Ryan on Feb 18, 2020\n",
    "# This approach uses the textacy library to extract noun chunks \n",
    "# and cross-ref with a list of bi-grams / tri-grams\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract a list of entities, we will exclude any noun chunks that are already entities\n",
    "ents = list(textacy.extract.entities(doc))\n",
    "\n",
    "themes = []\n",
    "for sent in doc.sents:\n",
    "\n",
    "    # Extract a list of noun chunks, filtering out any leading determiners\n",
    "    noun_chunks = list(textacy.extract.noun_chunks(sent, drop_determiners=True))\n",
    "    \n",
    "    # Extract a list of bi/tri-grams filtering out stop words, punctuation, numbers and noisy parts of speech\n",
    "    bi_grams = list(textacy.extract.ngrams(sent, 2, filter_stops=True, filter_punct=True, filter_nums=True, include_pos=[\"NOUN\",\"VERB\",\"ADJ\"]))\n",
    "    tri_grams = list(textacy.extract.ngrams(sent, 3, filter_stops=True, filter_punct=True, filter_nums=True, include_pos=[\"NOUN\",\"VERB\",\"ADJ\"]))\n",
    "    \n",
    "    # If chunk is in the bi/tri-gram list and not an entitie, add it to the themes list\n",
    "    for chunk in noun_chunks:   \n",
    "        if(chunk in bi_grams or chunk in tri_grams and chunk not in ents):\n",
    "            themes.append(chunk)\n",
    "        \n",
    "        # For one word chunks, ensure that word is a noun and not an entitiy\n",
    "        if(len(chunk) == 1 and chunk.root.pos_ == \"NOUN\" and chunk not in ents):\n",
    "            themes.append(chunk)\n",
    "                \n",
    "for theme in themes: print(theme)\n",
    "\n",
    "print(\"Total themes:\", len(themes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams using Textacy\n",
    "\n",
    "### Potential Issues:\n",
    "* Limited to bigrams, so 'free cash flow' gets split into 'free cash' and 'cash flow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lease operating\n",
      "operating expense\n",
      "unit basis\n",
      "flat year\n",
      "guidance range\n",
      "lowest rate\n",
      "natural gas\n",
      "gas company\n",
      "permanent switch\n",
      "premium drilling\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "bi_grams = list(textacy.extract.ngrams(doc, 2, filter_stops=True, filter_punct=True, filter_nums=True, include_pos=[\"NOUN\",\"VERB\",\"ADJ\"]))\n",
    "tri_grams = list(textacy.extract.ngrams(doc, 3, filter_stops=True, filter_punct=True, filter_nums=True, include_pos=[\"NOUN\",\"VERB\",\"ADJ\"]))\n",
    "\n",
    "ngrams = bi_grams + tri_grams \n",
    "\n",
    "for gram in ngrams[:10]:\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Terms using Textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('gas', 0.34029095892656264)\n",
      "('quarter', 0.34894857737527923)\n",
      "('year', 0.35748024872718487)\n",
      "('day', 0.3598592519105591)\n",
      "('oil', 0.39596369193405345)\n",
      "('barrel', 0.41454674227485694)\n",
      "('cost', 0.5229074238363266)\n",
      "('company', 0.524398786307582)\n",
      "('start', 0.5306848412269063)\n",
      "('price', 0.5359993208856335)\n"
     ]
    }
   ],
   "source": [
    "from textacy import ke\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "terms = list(ke.yake(doc, ngrams=1, topn=10, include_pos=[\"NOUN\"]))\n",
    "\n",
    "for term in terms:\n",
    "    print(term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER using Textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of 2019 ( DATE )\n",
      "year-over-year ( DATE )\n",
      "LOE ( ORG )\n",
      "4% ( PERCENT )\n",
      "2018 ( DATE )\n",
      "2019 ( DATE )\n",
      "DD&A ( ORG )\n",
      "12.65 ( MONEY )\n",
      "EOG ( ORG )\n",
      "D&A ( ORG )\n",
      "EOG ( ORG )\n",
      "third quarter ( DATE )\n",
      "Cheniere Energy. ( ORG )\n",
      "440 million ( MONEY )\n",
      "2020 ( DATE )\n",
      "Bakken ( ORG )\n",
      "Rockies ( ORG )\n",
      "Bakken ( ORG )\n",
      "quarter ( DATE )\n",
      "15 ( CARDINAL )\n",
      "2,150 barrels ( QUANTITY )\n",
      "300 barrels ( QUANTITY )\n",
      "2 million cubic feet ( QUANTITY )\n",
      "EOG ( ORG )\n",
      "quarter ( DATE )\n",
      "Clarks ( NORP )\n",
      "18\n",
      " ( DATE )\n",
      "Three Forks with an IP-30 ( ORG )\n",
      "3,800 barrels ( QUANTITY )\n",
      "Bakken ( GPE )\n",
      "quarter ( DATE )\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "entities = list(textacy.extract.entities(doc, drop_determiners=True, min_freq=0))\n",
    "\n",
    "for ent in entities:\n",
    "    print(ent.text, \"(\", ent.label_, \")\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER+ using Textacy\n",
    "\n",
    "### We can extract entities from the text using our language model and classify those entities into 18 different types including:\n",
    "* PERSON\tPeople, including fictional.\n",
    "* NORP\tNationalities or religious or political groups.\n",
    "* FAC\tBuildings, airports, highways, bridges, etc.\n",
    "* ORG\tCompanies, agencies, institutions, etc.\n",
    "* GPE\tCountries, cities, states.\n",
    "* LOC\tNon-GPE locations, mountain ranges, bodies of water.\n",
    "* PRODUCT\tObjects, vehicles, foods, etc. (Not services.)\n",
    "* EVENT\tNamed hurricanes, battles, wars, sports events, etc.\n",
    "* WORK_OF_ART\tTitles of books, songs, etc.\n",
    "* LAW\tNamed documents made into laws.\n",
    "* LANGUAGE\tAny named language.\n",
    "* **DATE\tAbsolute or relative dates or periods.**\n",
    "* TIME\tTimes smaller than a day.\n",
    "* PERCENT\tPercentage, including ”%“.\n",
    "* **MONEY\tMonetary values, including unit.**\n",
    "* **QUANTITY\tMeasurements, as of weight or distance.**\n",
    "* ORDINAL\t“first”, “second”, etc.\n",
    "* CARDINAL\tNumerals that do not fall under another type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRACTED ENTITIES:\n",
      "  start of 2019 (DATE)\n",
      "  year-over-year (DATE)\n",
      "  2018 (DATE)\n",
      "  2019 (DATE)\n",
      "  third quarter (DATE)\n",
      "  2020 (DATE)\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING DATES FROM THE TEXT\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "dates = list(textacy.extract.entities(doc, drop_determiners=True, min_freq=0, include_types=[\"DATE\"]))\n",
    "\n",
    "print(\"EXTRACTED ENTITIES:\")\n",
    "for date in dates[:6]:\n",
    "    print(\" \", date.text,\"(\"+date.label_+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRACTED ENTITIES:\n",
      "  12.65 (MONEY)\n",
      "  440 million (MONEY)\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING MONEY VALUES FROM THE TEXT\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "monies = list(textacy.extract.entities(doc, drop_determiners=True, min_freq=0, include_types=[\"MONEY\"]))\n",
    "\n",
    "print(\"EXTRACTED ENTITIES:\")\n",
    "for money in monies:\n",
    "    print(\" \", money.text,\"(\"+money.label_+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRACTED ENTITIES:\n",
      "  start of 2019 (DATE)\n",
      "  year-over-year (DATE)\n",
      "  4% (PERCENT)\n",
      "  2018 (DATE)\n",
      "  2019 (DATE)\n",
      "  12.65 (MONEY)\n",
      "  third quarter (DATE)\n",
      "  440 million (MONEY)\n",
      "  2020 (DATE)\n",
      "  quarter (DATE)\n",
      "  15 (CARDINAL)\n",
      "  2,150 barrels (QUANTITY)\n",
      "  300 barrels (QUANTITY)\n",
      "  2 million cubic feet (QUANTITY)\n",
      "  quarter (DATE)\n",
      "  18\n",
      " (DATE)\n",
      "  3,800 barrels (QUANTITY)\n",
      "  quarter (DATE)\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING QUANTITIES FROM THE TEXT\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "figures = list(textacy.extract.entities(doc, drop_determiners=True, min_freq=0, include_types=[\"NUMERIC\"]))\n",
    "\n",
    "print(\"EXTRACTED ENTITIES:\")\n",
    "for figure in figures:\n",
    "    print(\" \", figure.text,\"(\"+figure.label_+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
